{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8Cj_X1VnmC0"
   },
   "source": [
    "# PB016: Artificial intelligence I, labs 12 - Deep learning\n",
    "\n",
    "Today's topic is a quick and dirty introduction into deep learning. We'll focus namely on:\n",
    "1. __Dummy deep learning pipeline__\n",
    "2. __Developing your own deep learning classifier__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjLOiihWnmC1"
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Dummy deep learning pipeline\n",
    "\n",
    "__Basic facts__\n",
    "- Deep learning consists of designing, training and validating machine learning models based on various [neural architectures](https://en.wikipedia.org/wiki/Types_of_artificial_neural_networks) that typically involve multiple (hidden) layers consisting of many neural computing units (a simple example of one unit is [perceptron](https://en.wikipedia.org/wiki/Perceptron), such as the one we implemented in the previous labs).\n",
    "- An example of a deep learning architecture:\n",
    "\n",
    "<img src=\"https://www.fi.muni.cz/~novacek/courses/pb016/labs/img/stacked-representation.png\" alt=\"architecture\" width=\"550px\" title=\"Original image source: Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. ”Deep learning.” MIT press, 2016. (Chap. 1) License: Probably OK to use for academic purposes; for any other use, contact the publisher (MIT Press).\"/>\n",
    "\n",
    "- A number of libraries seamlessly integrating with parallel computational architectures is available for developing deep learning models. Some of the popular examples are:\n",
    " - [PyTorch](https://pytorch.org/) - originally a general-purpose ML library written in C, now a state-of-the-art deep learning framework with relatively easy-to-use Python (and C++) abstraction layers.\n",
    " - [TensorFlow](https://www.tensorflow.org/) - a general-purpose, highly optimised library for multilinear algebra and statistical learning.\n",
    " - [Keras](https://keras.io/) - formerly a separate project, now an abstraction layer for user-friendly development of deep learning models integrated with TensorFlow, PyTorch and [JAX](https://jax.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtRA1s8qdz2e"
   },
   "source": [
    "### A warm-up task - predicting onset of diabetes using Keras\n",
    "- This is based on a widely used PIMA Indians dataset - a classic machine learning sandbox data described in detail for instance [here](https://towardsdatascience.com/pima-indian-diabetes-prediction-7573698bd5fe).\n",
    "- The task is to use that dataset to train a classifier for predicting whether or not a person develops diabetes.\n",
    "- This is based on a number of characteristics (i.e., features) like blood pressure or body mass index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtWS3vDyd9pI"
   },
   "source": [
    "#### Loading the data using [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DvmXGN9OWh3O"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the library for handy CSV file processing\n",
    "import pandas as pd\n",
    "\n",
    "# loading the data, in CSV format, from the web\n",
    "dataframe = pd.read_csv('https://www.fi.muni.cz/~novacek/courses/pb016/labs/data/12/example/diabetes.csv')\n",
    "\n",
    "# checking the first few rows of the CSV\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzQWHmkmg3BZ"
   },
   "source": [
    "### Creating the data structures representing features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dYwVJCQng8gJ"
   },
   "outputs": [],
   "source": [
    "# getting just the Outcome column as the vector of labels\n",
    "# - note that the column contains 0, 1 values that correspond to negaive\n",
    "#   (no diabetes developed) and positive (diabetes developed) example labels,\n",
    "#   respectively\n",
    "df_labels = dataframe.Outcome.values.astype(float)\n",
    "# the features are the data minus the label vector\n",
    "# - this contains the remaining features present in the data\n",
    "df_features = dataframe.drop('Outcome',axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diBlgxl_hTCS"
   },
   "source": [
    "### Splitting the data into train and test sets using [scikit-learn](https://sklearn.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kL8i6lBXhWfi"
   },
   "outputs": [],
   "source": [
    "# importing a convenience data splitting function from scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# computing a random 80-20 split (80% training data, 20% of remaining\n",
    "# \"unseen\" data for testing the model trained on the 80%)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_features,df_labels,\\\n",
    "                                                    test_size=0.2,\\\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-r1dRs5fnRC"
   },
   "source": [
    "### Training a baseline, classical machine learning model (logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JGuqUIN3fmQL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cmZkFuIf01c"
   },
   "source": [
    "### Evaluating the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MxT6Axjdf2qp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x79c6b1c2ff50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using the trained model to predict the test labels\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "# importing stuff needed to display a confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# making plots prettier\n",
    "import seaborn as sns\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    logreg, x_test, y_test, xticks_rotation=\"vertical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0UFQvfFJf-3U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Various scores of the logistic regression classifier on the test set\n",
      "  - accuracy : 0.7597402597402597\n",
      "  - precision: 0.7390384615384615\n",
      "  - recall   : 0.7282828282828282\n",
      "  - F1       : 0.7326765188834155\n"
     ]
    }
   ],
   "source": [
    "# importing some widely-used scoring functions from scikit-klearn\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# computing the precision, recall and F1 scores from the predictions\n",
    "score_p = precision_score(y_test, y_pred, average='macro')\n",
    "score_r = recall_score(y_test, y_pred, average='macro')\n",
    "score_f = f1_score(y_test, y_pred, average='macro')\n",
    "# using a scoring method of the model itself (to compute accuracy)\n",
    "score_a = logreg.score(x_test, y_test)\n",
    "\n",
    "# printing out the scores\n",
    "print('Various scores of the logistic regression classifier on the test set')\n",
    "# the number of correct predictions (true positives and true negatives)\n",
    "# divided by the number of all predictions\n",
    "print('  - accuracy :', score_a)\n",
    "# the number of patients correctly classified as high risk\n",
    "# divided by the number of all patients classified as high risk\n",
    "print('  - precision:', score_p)\n",
    "# the number of patients correctly classified as high risk,\n",
    "# divided by the number of all patients that really are high risk\n",
    "print('  - recall   :', score_r)\n",
    "# aggregation of the precision and recall values (harmonic mean)\n",
    "print('  - F1       :', score_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paAJQMT6iAX2"
   },
   "source": [
    "### Creating a [Keras](https://keras.io/) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x3oWiAHwiC2y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 22:42:42.531277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733953362.573589 3761868 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733953362.583187 3761868 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 22:42:42.619035: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 22:42:47.075654: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# adapted from:\n",
    "#   - https://www.kaggle.com/code/atulnet/pima-diabetes-keras-implementation\n",
    "\n",
    "# importing the basics from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "# a model for simple sequential stacking of layers\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer: implicit input layer corresponding to the feature vector of size 8\n",
    "model.add(Input(shape=(8,)))\n",
    "# 2nd layer: 100 fully connected nodes, a simple non-linear activation\n",
    "#            (ReLU - rectified linear unit)\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer: dim=1, sigmoid activation\n",
    "#               (probability of the input characteristic of the positive class)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compiling the model with the binary cross-entropy loss (predicting 0/1)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXoiiGpCjaD0"
   },
   "source": [
    "### Training the created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "R0k0oJzyjb22",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7991 - loss: 0.4556 - val_accuracy: 0.6818 - val_loss: 0.6808\n",
      "Epoch 2/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7661 - loss: 0.4669 - val_accuracy: 0.7078 - val_loss: 0.6412\n",
      "Epoch 3/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7872 - loss: 0.4135 - val_accuracy: 0.6883 - val_loss: 0.7764\n",
      "Epoch 4/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7933 - loss: 0.4523 - val_accuracy: 0.6234 - val_loss: 0.8352\n",
      "Epoch 5/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7888 - loss: 0.4782 - val_accuracy: 0.7143 - val_loss: 0.6578\n",
      "Epoch 6/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8046 - loss: 0.4076 - val_accuracy: 0.6948 - val_loss: 0.6626\n",
      "Epoch 7/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8295 - loss: 0.4152 - val_accuracy: 0.7078 - val_loss: 0.6409\n",
      "Epoch 8/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7769 - loss: 0.4544 - val_accuracy: 0.7078 - val_loss: 0.6418\n",
      "Epoch 9/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7765 - loss: 0.4702 - val_accuracy: 0.6429 - val_loss: 0.6943\n",
      "Epoch 10/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7839 - loss: 0.4453 - val_accuracy: 0.6558 - val_loss: 0.6667\n",
      "Epoch 11/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7737 - loss: 0.4353 - val_accuracy: 0.7403 - val_loss: 0.7059\n",
      "Epoch 12/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7799 - loss: 0.4509 - val_accuracy: 0.6818 - val_loss: 0.6675\n",
      "Epoch 13/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7916 - loss: 0.4155 - val_accuracy: 0.6688 - val_loss: 0.6935\n",
      "Epoch 14/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7838 - loss: 0.4241 - val_accuracy: 0.6364 - val_loss: 0.6977\n",
      "Epoch 15/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7817 - loss: 0.4651 - val_accuracy: 0.6818 - val_loss: 0.6639\n",
      "Epoch 16/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7950 - loss: 0.3964 - val_accuracy: 0.6753 - val_loss: 0.7100\n",
      "Epoch 17/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7836 - loss: 0.4590 - val_accuracy: 0.6039 - val_loss: 0.8242\n",
      "Epoch 18/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7881 - loss: 0.4904 - val_accuracy: 0.6558 - val_loss: 0.6699\n",
      "Epoch 19/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7830 - loss: 0.4167 - val_accuracy: 0.7143 - val_loss: 0.6420\n",
      "Epoch 20/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8024 - loss: 0.4160 - val_accuracy: 0.7078 - val_loss: 0.6450\n",
      "Epoch 21/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7766 - loss: 0.4661 - val_accuracy: 0.7013 - val_loss: 0.6603\n",
      "Epoch 22/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8190 - loss: 0.4075 - val_accuracy: 0.6948 - val_loss: 0.6556\n",
      "Epoch 23/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8058 - loss: 0.4063 - val_accuracy: 0.7143 - val_loss: 0.6612\n",
      "Epoch 24/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7757 - loss: 0.4742 - val_accuracy: 0.7078 - val_loss: 0.6756\n",
      "Epoch 25/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7596 - loss: 0.4574 - val_accuracy: 0.7013 - val_loss: 0.6685\n",
      "Epoch 26/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8102 - loss: 0.4233 - val_accuracy: 0.6948 - val_loss: 0.6570\n",
      "Epoch 27/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7781 - loss: 0.4378 - val_accuracy: 0.7013 - val_loss: 0.7352\n",
      "Epoch 28/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7665 - loss: 0.5001 - val_accuracy: 0.6883 - val_loss: 0.8917\n",
      "Epoch 29/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7468 - loss: 0.5699 - val_accuracy: 0.6623 - val_loss: 0.7557\n",
      "Epoch 30/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7574 - loss: 0.4949 - val_accuracy: 0.6623 - val_loss: 0.7226\n",
      "Epoch 31/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7598 - loss: 0.4572 - val_accuracy: 0.6883 - val_loss: 0.6542\n",
      "Epoch 32/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8050 - loss: 0.4196 - val_accuracy: 0.7208 - val_loss: 0.6574\n",
      "Epoch 33/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8052 - loss: 0.4329 - val_accuracy: 0.6883 - val_loss: 0.6587\n",
      "Epoch 34/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.4443 - val_accuracy: 0.7078 - val_loss: 0.6500\n",
      "Epoch 35/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7931 - loss: 0.4344 - val_accuracy: 0.6623 - val_loss: 0.6943\n",
      "Epoch 36/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8331 - loss: 0.4051 - val_accuracy: 0.6753 - val_loss: 0.7474\n",
      "Epoch 37/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7588 - loss: 0.5143 - val_accuracy: 0.6883 - val_loss: 0.7259\n",
      "Epoch 38/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7961 - loss: 0.4113 - val_accuracy: 0.6558 - val_loss: 0.7552\n",
      "Epoch 39/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8069 - loss: 0.4514 - val_accuracy: 0.6429 - val_loss: 0.7108\n",
      "Epoch 40/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8191 - loss: 0.4062 - val_accuracy: 0.7013 - val_loss: 0.6745\n",
      "Epoch 41/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8131 - loss: 0.4288 - val_accuracy: 0.6948 - val_loss: 0.7451\n",
      "Epoch 42/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.3988 - val_accuracy: 0.6688 - val_loss: 0.9103\n",
      "Epoch 43/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7717 - loss: 0.5159 - val_accuracy: 0.6883 - val_loss: 0.6993\n",
      "Epoch 44/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.4524 - val_accuracy: 0.6494 - val_loss: 0.7393\n",
      "Epoch 45/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7851 - loss: 0.4660 - val_accuracy: 0.6948 - val_loss: 0.6430\n",
      "Epoch 46/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8096 - loss: 0.4105 - val_accuracy: 0.6818 - val_loss: 0.6873\n",
      "Epoch 47/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7653 - loss: 0.4541 - val_accuracy: 0.6623 - val_loss: 0.6836\n",
      "Epoch 48/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.3978 - val_accuracy: 0.6623 - val_loss: 0.6846\n",
      "Epoch 49/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8148 - loss: 0.4261 - val_accuracy: 0.6753 - val_loss: 0.8085\n",
      "Epoch 50/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7119 - loss: 0.6102 - val_accuracy: 0.7338 - val_loss: 0.7447\n",
      "Epoch 51/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7628 - loss: 0.5234 - val_accuracy: 0.6753 - val_loss: 0.6580\n",
      "Epoch 52/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7994 - loss: 0.4085 - val_accuracy: 0.7078 - val_loss: 0.6591\n",
      "Epoch 53/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8194 - loss: 0.3959 - val_accuracy: 0.6299 - val_loss: 0.7216\n",
      "Epoch 54/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7870 - loss: 0.4470 - val_accuracy: 0.6753 - val_loss: 0.7056\n",
      "Epoch 55/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7767 - loss: 0.4483 - val_accuracy: 0.7013 - val_loss: 0.6759\n",
      "Epoch 56/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8365 - loss: 0.3665 - val_accuracy: 0.6948 - val_loss: 0.7520\n",
      "Epoch 57/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8060 - loss: 0.3940 - val_accuracy: 0.6688 - val_loss: 0.6923\n",
      "Epoch 58/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7997 - loss: 0.4247 - val_accuracy: 0.6688 - val_loss: 0.7098\n",
      "Epoch 59/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7866 - loss: 0.4580 - val_accuracy: 0.6753 - val_loss: 0.6986\n",
      "Epoch 60/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7439 - loss: 0.5102 - val_accuracy: 0.6623 - val_loss: 0.8272\n",
      "Epoch 61/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7524 - loss: 0.4552 - val_accuracy: 0.6494 - val_loss: 0.6909\n",
      "Epoch 62/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8130 - loss: 0.4184 - val_accuracy: 0.6623 - val_loss: 0.7435\n",
      "Epoch 63/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7808 - loss: 0.4445 - val_accuracy: 0.6883 - val_loss: 0.6639\n",
      "Epoch 64/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8349 - loss: 0.3910 - val_accuracy: 0.6883 - val_loss: 0.7039\n",
      "Epoch 65/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7894 - loss: 0.4259 - val_accuracy: 0.7013 - val_loss: 0.6692\n",
      "Epoch 66/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8023 - loss: 0.3957 - val_accuracy: 0.7143 - val_loss: 0.6785\n",
      "Epoch 67/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.4100 - val_accuracy: 0.7403 - val_loss: 0.6471\n",
      "Epoch 68/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8107 - loss: 0.3923 - val_accuracy: 0.6948 - val_loss: 0.6739\n",
      "Epoch 69/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7960 - loss: 0.4183 - val_accuracy: 0.6818 - val_loss: 0.6919\n",
      "Epoch 70/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8165 - loss: 0.4093 - val_accuracy: 0.7403 - val_loss: 0.6635\n",
      "Epoch 71/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8166 - loss: 0.4118 - val_accuracy: 0.6883 - val_loss: 0.6837\n",
      "Epoch 72/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8016 - loss: 0.4217 - val_accuracy: 0.6948 - val_loss: 0.8335\n",
      "Epoch 73/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6829 - loss: 0.5641 - val_accuracy: 0.7143 - val_loss: 0.7023\n",
      "Epoch 74/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7739 - loss: 0.4492 - val_accuracy: 0.6753 - val_loss: 0.7012\n",
      "Epoch 75/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8179 - loss: 0.4079 - val_accuracy: 0.6299 - val_loss: 0.8335\n",
      "Epoch 76/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7651 - loss: 0.4868 - val_accuracy: 0.6753 - val_loss: 0.6845\n",
      "Epoch 77/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8231 - loss: 0.3949 - val_accuracy: 0.6883 - val_loss: 0.7470\n",
      "Epoch 78/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7888 - loss: 0.4528 - val_accuracy: 0.7143 - val_loss: 0.6518\n",
      "Epoch 79/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7952 - loss: 0.3921 - val_accuracy: 0.6818 - val_loss: 0.7054\n",
      "Epoch 80/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8076 - loss: 0.4251 - val_accuracy: 0.7273 - val_loss: 0.6802\n",
      "Epoch 81/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8158 - loss: 0.4032 - val_accuracy: 0.6948 - val_loss: 0.6708\n",
      "Epoch 82/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4049 - val_accuracy: 0.6429 - val_loss: 0.7128\n",
      "Epoch 83/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8273 - loss: 0.4093 - val_accuracy: 0.6818 - val_loss: 0.6985\n",
      "Epoch 84/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8219 - loss: 0.3992 - val_accuracy: 0.6948 - val_loss: 0.6637\n",
      "Epoch 85/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8215 - loss: 0.3887 - val_accuracy: 0.7208 - val_loss: 0.6917\n",
      "Epoch 86/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8104 - loss: 0.4199 - val_accuracy: 0.7013 - val_loss: 0.6825\n",
      "Epoch 87/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.4014 - val_accuracy: 0.6818 - val_loss: 0.6843\n",
      "Epoch 88/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8457 - loss: 0.3760 - val_accuracy: 0.6688 - val_loss: 0.7251\n",
      "Epoch 89/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7816 - loss: 0.4538 - val_accuracy: 0.6429 - val_loss: 0.7048\n",
      "Epoch 90/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8343 - loss: 0.3766 - val_accuracy: 0.6364 - val_loss: 0.7419\n",
      "Epoch 91/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7842 - loss: 0.4463 - val_accuracy: 0.7273 - val_loss: 0.6749\n",
      "Epoch 92/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7897 - loss: 0.4167 - val_accuracy: 0.7013 - val_loss: 0.8081\n",
      "Epoch 93/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8066 - loss: 0.4038 - val_accuracy: 0.7078 - val_loss: 0.6753\n",
      "Epoch 94/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8232 - loss: 0.3906 - val_accuracy: 0.6299 - val_loss: 0.8508\n",
      "Epoch 95/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7415 - loss: 0.4939 - val_accuracy: 0.7208 - val_loss: 0.7505\n",
      "Epoch 96/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7875 - loss: 0.4484 - val_accuracy: 0.6948 - val_loss: 0.7598\n",
      "Epoch 97/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.4643 - val_accuracy: 0.7338 - val_loss: 0.7335\n",
      "Epoch 98/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8047 - loss: 0.4083 - val_accuracy: 0.7532 - val_loss: 0.7194\n",
      "Epoch 99/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8132 - loss: 0.4086 - val_accuracy: 0.6883 - val_loss: 0.7459\n",
      "Epoch 100/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7457 - loss: 0.4650 - val_accuracy: 0.6948 - val_loss: 0.7180\n",
      "Epoch 101/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8156 - loss: 0.4081 - val_accuracy: 0.6623 - val_loss: 0.8009\n",
      "Epoch 102/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7795 - loss: 0.4442 - val_accuracy: 0.6364 - val_loss: 0.7728\n",
      "Epoch 103/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7923 - loss: 0.4561 - val_accuracy: 0.6883 - val_loss: 0.6862\n",
      "Epoch 104/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8501 - loss: 0.3537 - val_accuracy: 0.7338 - val_loss: 0.6730\n",
      "Epoch 105/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8399 - loss: 0.3669 - val_accuracy: 0.6948 - val_loss: 0.6981\n",
      "Epoch 106/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8242 - loss: 0.3860 - val_accuracy: 0.7468 - val_loss: 0.7270\n",
      "Epoch 107/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7827 - loss: 0.4252 - val_accuracy: 0.7338 - val_loss: 0.6599\n",
      "Epoch 108/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8189 - loss: 0.3880 - val_accuracy: 0.6948 - val_loss: 0.7274\n",
      "Epoch 109/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8307 - loss: 0.3818 - val_accuracy: 0.7403 - val_loss: 0.6615\n",
      "Epoch 110/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8044 - loss: 0.4119 - val_accuracy: 0.7338 - val_loss: 0.6636\n",
      "Epoch 111/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8299 - loss: 0.3777 - val_accuracy: 0.7208 - val_loss: 0.6844\n",
      "Epoch 112/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8082 - loss: 0.4330 - val_accuracy: 0.6883 - val_loss: 0.6564\n",
      "Epoch 113/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8413 - loss: 0.3871 - val_accuracy: 0.7143 - val_loss: 0.6816\n",
      "Epoch 114/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7832 - loss: 0.4146 - val_accuracy: 0.6883 - val_loss: 0.6811\n",
      "Epoch 115/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8380 - loss: 0.3711 - val_accuracy: 0.6883 - val_loss: 0.7237\n",
      "Epoch 116/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7895 - loss: 0.4483 - val_accuracy: 0.6753 - val_loss: 0.6919\n",
      "Epoch 117/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8008 - loss: 0.4743 - val_accuracy: 0.6753 - val_loss: 0.7509\n",
      "Epoch 118/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8144 - loss: 0.4142 - val_accuracy: 0.6104 - val_loss: 0.8551\n",
      "Epoch 119/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7844 - loss: 0.4635 - val_accuracy: 0.5909 - val_loss: 0.8633\n",
      "Epoch 120/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7798 - loss: 0.4823 - val_accuracy: 0.6818 - val_loss: 0.7229\n",
      "Epoch 121/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8276 - loss: 0.3847 - val_accuracy: 0.6688 - val_loss: 0.7323\n",
      "Epoch 122/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8118 - loss: 0.4244 - val_accuracy: 0.7013 - val_loss: 0.6711\n",
      "Epoch 123/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7954 - loss: 0.3964 - val_accuracy: 0.6494 - val_loss: 0.7449\n",
      "Epoch 124/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7929 - loss: 0.4229 - val_accuracy: 0.6299 - val_loss: 0.8126\n",
      "Epoch 125/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8098 - loss: 0.4173 - val_accuracy: 0.6818 - val_loss: 0.8535\n",
      "Epoch 126/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7516 - loss: 0.5149 - val_accuracy: 0.6753 - val_loss: 0.6892\n",
      "Epoch 127/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7978 - loss: 0.4083 - val_accuracy: 0.7013 - val_loss: 0.6818\n",
      "Epoch 128/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8082 - loss: 0.4171 - val_accuracy: 0.6558 - val_loss: 0.7558\n",
      "Epoch 129/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7830 - loss: 0.4747 - val_accuracy: 0.6234 - val_loss: 0.8567\n",
      "Epoch 130/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7757 - loss: 0.4888 - val_accuracy: 0.6948 - val_loss: 0.8483\n",
      "Epoch 131/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7907 - loss: 0.4363 - val_accuracy: 0.6818 - val_loss: 0.7988\n",
      "Epoch 132/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8163 - loss: 0.4382 - val_accuracy: 0.6883 - val_loss: 0.7179\n",
      "Epoch 133/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8374 - loss: 0.4009 - val_accuracy: 0.7273 - val_loss: 0.7075\n",
      "Epoch 134/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8002 - loss: 0.4198 - val_accuracy: 0.6299 - val_loss: 0.9640\n",
      "Epoch 135/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7431 - loss: 0.5465 - val_accuracy: 0.7273 - val_loss: 0.6717\n",
      "Epoch 136/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8116 - loss: 0.3832 - val_accuracy: 0.6558 - val_loss: 0.7815\n",
      "Epoch 137/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7849 - loss: 0.4026 - val_accuracy: 0.6364 - val_loss: 0.8447\n",
      "Epoch 138/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7920 - loss: 0.4329 - val_accuracy: 0.6948 - val_loss: 0.6820\n",
      "Epoch 139/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8144 - loss: 0.4090 - val_accuracy: 0.7078 - val_loss: 0.6742\n",
      "Epoch 140/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8334 - loss: 0.3637 - val_accuracy: 0.7208 - val_loss: 0.6730\n",
      "Epoch 141/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8258 - loss: 0.3888 - val_accuracy: 0.6688 - val_loss: 0.7208\n",
      "Epoch 142/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8101 - loss: 0.4090 - val_accuracy: 0.7078 - val_loss: 0.6714\n",
      "Epoch 143/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8473 - loss: 0.3785 - val_accuracy: 0.6948 - val_loss: 0.7462\n",
      "Epoch 144/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7928 - loss: 0.4265 - val_accuracy: 0.7013 - val_loss: 0.7312\n",
      "Epoch 145/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.4762 - val_accuracy: 0.7013 - val_loss: 0.7373\n",
      "Epoch 146/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7665 - loss: 0.5137 - val_accuracy: 0.6623 - val_loss: 0.8961\n",
      "Epoch 147/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7524 - loss: 0.5278 - val_accuracy: 0.7143 - val_loss: 0.7025\n",
      "Epoch 148/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.3996 - val_accuracy: 0.7013 - val_loss: 0.7546\n",
      "Epoch 149/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7918 - loss: 0.4242 - val_accuracy: 0.7208 - val_loss: 0.6714\n",
      "Epoch 150/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8203 - loss: 0.3796 - val_accuracy: 0.6948 - val_loss: 0.6790\n",
      "Epoch 151/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8242 - loss: 0.3998 - val_accuracy: 0.7078 - val_loss: 0.7030\n",
      "Epoch 152/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8251 - loss: 0.4270 - val_accuracy: 0.7143 - val_loss: 0.7524\n",
      "Epoch 153/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 0.4081 - val_accuracy: 0.6818 - val_loss: 0.7344\n",
      "Epoch 154/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8214 - loss: 0.4154 - val_accuracy: 0.7078 - val_loss: 0.7111\n",
      "Epoch 155/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.4070 - val_accuracy: 0.6948 - val_loss: 0.7806\n",
      "Epoch 156/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.4276 - val_accuracy: 0.6558 - val_loss: 0.7222\n",
      "Epoch 157/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.3722 - val_accuracy: 0.7143 - val_loss: 0.6924\n",
      "Epoch 158/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.3882 - val_accuracy: 0.6299 - val_loss: 0.8145\n",
      "Epoch 159/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7749 - loss: 0.4853 - val_accuracy: 0.7013 - val_loss: 0.7009\n",
      "Epoch 160/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.4267 - val_accuracy: 0.7403 - val_loss: 0.6860\n",
      "Epoch 161/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.3731 - val_accuracy: 0.7143 - val_loss: 0.6927\n",
      "Epoch 162/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.4608 - val_accuracy: 0.6688 - val_loss: 0.7414\n",
      "Epoch 163/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8401 - loss: 0.3685 - val_accuracy: 0.7468 - val_loss: 0.6801\n",
      "Epoch 164/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.4281 - val_accuracy: 0.7403 - val_loss: 0.7242\n",
      "Epoch 165/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.3732 - val_accuracy: 0.6753 - val_loss: 0.7760\n",
      "Epoch 166/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4038 - val_accuracy: 0.6623 - val_loss: 0.7347\n",
      "Epoch 167/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 0.3811 - val_accuracy: 0.6429 - val_loss: 0.8003\n",
      "Epoch 168/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.4536 - val_accuracy: 0.7013 - val_loss: 0.7110\n",
      "Epoch 169/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8045 - loss: 0.4289 - val_accuracy: 0.6818 - val_loss: 0.7680\n",
      "Epoch 170/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.4033 - val_accuracy: 0.7078 - val_loss: 0.6979\n",
      "Epoch 171/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 0.3351 - val_accuracy: 0.6429 - val_loss: 0.8196\n",
      "Epoch 172/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7372 - loss: 0.4844 - val_accuracy: 0.7208 - val_loss: 0.7059\n",
      "Epoch 173/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8021 - loss: 0.4003 - val_accuracy: 0.7013 - val_loss: 0.7074\n",
      "Epoch 174/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.4134 - val_accuracy: 0.6753 - val_loss: 0.7709\n",
      "Epoch 175/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 0.4225 - val_accuracy: 0.7143 - val_loss: 0.6955\n",
      "Epoch 176/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.4104 - val_accuracy: 0.6688 - val_loss: 0.8390\n",
      "Epoch 177/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 0.4543 - val_accuracy: 0.6688 - val_loss: 0.7355\n",
      "Epoch 178/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8067 - loss: 0.4164 - val_accuracy: 0.6753 - val_loss: 0.7179\n",
      "Epoch 179/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8034 - loss: 0.4094 - val_accuracy: 0.7013 - val_loss: 0.7028\n",
      "Epoch 180/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7793 - loss: 0.4515 - val_accuracy: 0.7143 - val_loss: 0.7249\n",
      "Epoch 181/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 0.3968 - val_accuracy: 0.6883 - val_loss: 0.6851\n",
      "Epoch 182/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7874 - loss: 0.4287 - val_accuracy: 0.6948 - val_loss: 0.8501\n",
      "Epoch 183/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7807 - loss: 0.4583 - val_accuracy: 0.6623 - val_loss: 0.7311\n",
      "Epoch 184/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.3900 - val_accuracy: 0.6558 - val_loss: 0.8509\n",
      "Epoch 185/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7765 - loss: 0.4675 - val_accuracy: 0.7338 - val_loss: 0.7360\n",
      "Epoch 186/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4001 - val_accuracy: 0.7078 - val_loss: 0.6973\n",
      "Epoch 187/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8056 - loss: 0.3927 - val_accuracy: 0.6883 - val_loss: 0.7031\n",
      "Epoch 188/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8148 - loss: 0.3872 - val_accuracy: 0.7078 - val_loss: 0.6921\n",
      "Epoch 189/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.3570 - val_accuracy: 0.7208 - val_loss: 0.7172\n",
      "Epoch 190/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.3568 - val_accuracy: 0.7078 - val_loss: 0.6969\n",
      "Epoch 191/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.3543 - val_accuracy: 0.6948 - val_loss: 0.6871\n",
      "Epoch 192/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4067 - val_accuracy: 0.7143 - val_loss: 0.6891\n",
      "Epoch 193/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 0.3654 - val_accuracy: 0.6299 - val_loss: 0.7886\n",
      "Epoch 194/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.4196 - val_accuracy: 0.7013 - val_loss: 0.8014\n",
      "Epoch 195/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8020 - loss: 0.4216 - val_accuracy: 0.6883 - val_loss: 0.7604\n",
      "Epoch 196/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.4108 - val_accuracy: 0.6558 - val_loss: 0.7611\n",
      "Epoch 197/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.3955 - val_accuracy: 0.7143 - val_loss: 0.7185\n",
      "Epoch 198/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8188 - loss: 0.3898 - val_accuracy: 0.6948 - val_loss: 0.7672\n",
      "Epoch 199/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.4002 - val_accuracy: 0.7338 - val_loss: 0.7203\n",
      "Epoch 200/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.4392 - val_accuracy: 0.7208 - val_loss: 0.7733\n",
      "Epoch 201/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.4286 - val_accuracy: 0.6883 - val_loss: 0.7305\n",
      "Epoch 202/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8322 - loss: 0.3583 - val_accuracy: 0.6948 - val_loss: 0.8478\n",
      "Epoch 203/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4528 - val_accuracy: 0.7013 - val_loss: 0.7420\n",
      "Epoch 204/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 0.4161 - val_accuracy: 0.6818 - val_loss: 0.7806\n",
      "Epoch 205/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7932 - loss: 0.4511 - val_accuracy: 0.6818 - val_loss: 0.7109\n",
      "Epoch 206/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8332 - loss: 0.3715 - val_accuracy: 0.7078 - val_loss: 0.8007\n",
      "Epoch 207/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.4482 - val_accuracy: 0.7013 - val_loss: 0.7579\n",
      "Epoch 208/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8305 - loss: 0.3651 - val_accuracy: 0.7143 - val_loss: 0.7391\n",
      "Epoch 209/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8418 - loss: 0.3554 - val_accuracy: 0.7078 - val_loss: 0.7110\n",
      "Epoch 210/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7991 - loss: 0.3872 - val_accuracy: 0.6948 - val_loss: 0.7370\n",
      "Epoch 211/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8371 - loss: 0.3653 - val_accuracy: 0.7013 - val_loss: 0.7291\n",
      "Epoch 212/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8151 - loss: 0.4107 - val_accuracy: 0.6818 - val_loss: 0.9618\n",
      "Epoch 213/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.5223 - val_accuracy: 0.6948 - val_loss: 0.7627\n",
      "Epoch 214/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.3875 - val_accuracy: 0.7208 - val_loss: 0.7459\n",
      "Epoch 215/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.3547 - val_accuracy: 0.6818 - val_loss: 0.7490\n",
      "Epoch 216/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8033 - loss: 0.3845 - val_accuracy: 0.6883 - val_loss: 0.7359\n",
      "Epoch 217/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7976 - loss: 0.4020 - val_accuracy: 0.6623 - val_loss: 0.7395\n",
      "Epoch 218/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8234 - loss: 0.3787 - val_accuracy: 0.7273 - val_loss: 0.7046\n",
      "Epoch 219/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7798 - loss: 0.4239 - val_accuracy: 0.7338 - val_loss: 0.7232\n",
      "Epoch 220/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8291 - loss: 0.3912 - val_accuracy: 0.7597 - val_loss: 0.7488\n",
      "Epoch 221/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8192 - loss: 0.3808 - val_accuracy: 0.7143 - val_loss: 0.7561\n",
      "Epoch 222/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8246 - loss: 0.3530 - val_accuracy: 0.6948 - val_loss: 0.7608\n",
      "Epoch 223/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8117 - loss: 0.3937 - val_accuracy: 0.6883 - val_loss: 0.7555\n",
      "Epoch 224/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.3551 - val_accuracy: 0.6364 - val_loss: 0.7806\n",
      "Epoch 225/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8112 - loss: 0.4106 - val_accuracy: 0.6948 - val_loss: 0.7392\n",
      "Epoch 226/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 0.3757 - val_accuracy: 0.7273 - val_loss: 0.7239\n",
      "Epoch 227/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8497 - loss: 0.3360 - val_accuracy: 0.7273 - val_loss: 0.7323\n",
      "Epoch 228/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8625 - loss: 0.3526 - val_accuracy: 0.6753 - val_loss: 0.7226\n",
      "Epoch 229/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8445 - loss: 0.3477 - val_accuracy: 0.6364 - val_loss: 0.8643\n",
      "Epoch 230/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7338 - loss: 0.5182 - val_accuracy: 0.7078 - val_loss: 0.8201\n",
      "Epoch 231/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8177 - loss: 0.3957 - val_accuracy: 0.7273 - val_loss: 0.7076\n",
      "Epoch 232/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.3596 - val_accuracy: 0.6753 - val_loss: 0.7781\n",
      "Epoch 233/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8244 - loss: 0.3702 - val_accuracy: 0.7208 - val_loss: 0.7071\n",
      "Epoch 234/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8032 - loss: 0.3707 - val_accuracy: 0.6883 - val_loss: 0.7208\n",
      "Epoch 235/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - loss: 0.3615 - val_accuracy: 0.7273 - val_loss: 0.7050\n",
      "Epoch 236/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8216 - loss: 0.3987 - val_accuracy: 0.6818 - val_loss: 0.7141\n",
      "Epoch 237/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7918 - loss: 0.4406 - val_accuracy: 0.6623 - val_loss: 0.7398\n",
      "Epoch 238/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7672 - loss: 0.4750 - val_accuracy: 0.6948 - val_loss: 0.8033\n",
      "Epoch 239/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.4016 - val_accuracy: 0.7078 - val_loss: 0.8164\n",
      "Epoch 240/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.5120 - val_accuracy: 0.7273 - val_loss: 0.7140\n",
      "Epoch 241/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8064 - loss: 0.3810 - val_accuracy: 0.6948 - val_loss: 0.8063\n",
      "Epoch 242/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.4405 - val_accuracy: 0.7208 - val_loss: 0.7322\n",
      "Epoch 243/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7885 - loss: 0.4487 - val_accuracy: 0.6429 - val_loss: 0.8761\n",
      "Epoch 244/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.4785 - val_accuracy: 0.6948 - val_loss: 0.7332\n",
      "Epoch 245/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8246 - loss: 0.3675 - val_accuracy: 0.7013 - val_loss: 0.7187\n",
      "Epoch 246/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.3592 - val_accuracy: 0.6818 - val_loss: 0.7588\n",
      "Epoch 247/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.3788 - val_accuracy: 0.6948 - val_loss: 0.9039\n",
      "Epoch 248/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7931 - loss: 0.4756 - val_accuracy: 0.7013 - val_loss: 0.7593\n",
      "Epoch 249/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7765 - loss: 0.3979 - val_accuracy: 0.7208 - val_loss: 0.7290\n",
      "Epoch 250/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4352 - val_accuracy: 0.7078 - val_loss: 0.7584\n",
      "Epoch 251/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8214 - loss: 0.3923 - val_accuracy: 0.6688 - val_loss: 0.7679\n",
      "Epoch 252/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4319 - val_accuracy: 0.6818 - val_loss: 0.7370\n",
      "Epoch 253/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8173 - loss: 0.3527 - val_accuracy: 0.7013 - val_loss: 0.7743\n",
      "Epoch 254/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8078 - loss: 0.4010 - val_accuracy: 0.7013 - val_loss: 0.7285\n",
      "Epoch 255/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 0.3373 - val_accuracy: 0.6883 - val_loss: 0.7752\n",
      "Epoch 256/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8368 - loss: 0.3464 - val_accuracy: 0.7143 - val_loss: 0.7265\n",
      "Epoch 257/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8229 - loss: 0.3833 - val_accuracy: 0.7143 - val_loss: 0.7437\n",
      "Epoch 258/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8210 - loss: 0.4013 - val_accuracy: 0.7208 - val_loss: 0.7277\n",
      "Epoch 259/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.3637 - val_accuracy: 0.7013 - val_loss: 0.7548\n",
      "Epoch 260/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.3706 - val_accuracy: 0.6883 - val_loss: 0.7617\n",
      "Epoch 261/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7978 - loss: 0.4024 - val_accuracy: 0.6558 - val_loss: 0.7666\n",
      "Epoch 262/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8135 - loss: 0.4141 - val_accuracy: 0.6883 - val_loss: 0.7882\n",
      "Epoch 263/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3435 - val_accuracy: 0.6948 - val_loss: 0.7533\n",
      "Epoch 264/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.3980 - val_accuracy: 0.6169 - val_loss: 0.9458\n",
      "Epoch 265/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7613 - loss: 0.4825 - val_accuracy: 0.7013 - val_loss: 1.0047\n",
      "Epoch 266/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 0.4192 - val_accuracy: 0.6429 - val_loss: 0.8065\n",
      "Epoch 267/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8080 - loss: 0.3757 - val_accuracy: 0.6364 - val_loss: 0.8441\n",
      "Epoch 268/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8205 - loss: 0.3916 - val_accuracy: 0.6883 - val_loss: 0.9451\n",
      "Epoch 269/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.4439 - val_accuracy: 0.6688 - val_loss: 0.8093\n",
      "Epoch 270/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.4075 - val_accuracy: 0.7208 - val_loss: 0.8250\n",
      "Epoch 271/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7966 - loss: 0.4136 - val_accuracy: 0.7143 - val_loss: 0.7644\n",
      "Epoch 272/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 0.3974 - val_accuracy: 0.6558 - val_loss: 0.7889\n",
      "Epoch 273/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8445 - loss: 0.3844 - val_accuracy: 0.6883 - val_loss: 0.7417\n",
      "Epoch 274/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7668 - loss: 0.4977 - val_accuracy: 0.7013 - val_loss: 1.0142\n",
      "Epoch 275/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.4357 - val_accuracy: 0.6623 - val_loss: 0.9399\n",
      "Epoch 276/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7799 - loss: 0.5012 - val_accuracy: 0.7273 - val_loss: 0.7995\n",
      "Epoch 277/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.3836 - val_accuracy: 0.6753 - val_loss: 0.7834\n",
      "Epoch 278/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8416 - loss: 0.3549 - val_accuracy: 0.7143 - val_loss: 0.7132\n",
      "Epoch 279/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8474 - loss: 0.3419 - val_accuracy: 0.7208 - val_loss: 0.7354\n",
      "Epoch 280/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8108 - loss: 0.3788 - val_accuracy: 0.7338 - val_loss: 0.8610\n",
      "Epoch 281/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7789 - loss: 0.4982 - val_accuracy: 0.7143 - val_loss: 0.8522\n",
      "Epoch 282/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7799 - loss: 0.4935 - val_accuracy: 0.6169 - val_loss: 1.0256\n",
      "Epoch 283/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.4193 - val_accuracy: 0.7078 - val_loss: 0.7406\n",
      "Epoch 284/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8116 - loss: 0.3863 - val_accuracy: 0.7078 - val_loss: 0.8123\n",
      "Epoch 285/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.3697 - val_accuracy: 0.7013 - val_loss: 0.7496\n",
      "Epoch 286/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.3543 - val_accuracy: 0.7013 - val_loss: 0.7302\n",
      "Epoch 287/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7894 - loss: 0.4217 - val_accuracy: 0.7078 - val_loss: 0.7446\n",
      "Epoch 288/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.3522 - val_accuracy: 0.7078 - val_loss: 0.9110\n",
      "Epoch 289/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8136 - loss: 0.4081 - val_accuracy: 0.7208 - val_loss: 0.7246\n",
      "Epoch 290/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3659 - val_accuracy: 0.6883 - val_loss: 0.8032\n",
      "Epoch 291/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8562 - loss: 0.3646 - val_accuracy: 0.7208 - val_loss: 0.7638\n",
      "Epoch 292/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7965 - loss: 0.4360 - val_accuracy: 0.6883 - val_loss: 0.8491\n",
      "Epoch 293/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.3946 - val_accuracy: 0.7208 - val_loss: 0.7352\n",
      "Epoch 294/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.3257 - val_accuracy: 0.6883 - val_loss: 0.7582\n",
      "Epoch 295/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8248 - loss: 0.3863 - val_accuracy: 0.6753 - val_loss: 0.7569\n",
      "Epoch 296/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8612 - loss: 0.3379 - val_accuracy: 0.7078 - val_loss: 0.7229\n",
      "Epoch 297/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8332 - loss: 0.3532 - val_accuracy: 0.6883 - val_loss: 0.7439\n",
      "Epoch 298/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8292 - loss: 0.3729 - val_accuracy: 0.6948 - val_loss: 0.7360\n",
      "Epoch 299/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.3706 - val_accuracy: 0.7143 - val_loss: 0.7238\n",
      "Epoch 300/300\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8313 - loss: 0.3802 - val_accuracy: 0.7078 - val_loss: 0.7253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x79c657583b90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simply calling the fit function, training on the training data and validating\n",
    "# on the test data after each epoch\n",
    "model.fit(x_train,y_train,epochs=300,\\\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(1, 0, '0'), Text(2, 0, '1')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAheUlEQVR4nO3df0xV9/3H8Rfc1gtEsG2ogJbukqHjNlIQqAiWTRJW1hW/EspidFTDql272nS9ulWsxbmu0O8qjm6yMdsat7i2rpSSDY1Nx0ZK9S5GqElJoOoq1VQuapoKRYTtXr5/NNDdr/jjwsXP5fp8JKTh3M85901S67OHc84NGR4eHhYAAIAhoaYHAAAANzZiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEbdZHqAa+HxeHT69GlFRkYqJCTE9DgAAOAaDA8Pq6+vT7NmzVJo6OXPf0yJGDl9+rTi4+NNjwEAAMbh1KlTuuOOOy77+pSIkcjISElf/jBRUVGGpwEAANeit7dX8fHxo3+PX86UiJGRX81ERUURIwAATDFXu8SCC1gBAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACM8jlG3nvvPS1ZskSzZs1SSEiIGhoarrpPc3Oz0tLSZLValZiYqF27do1jVAAAEIx8jpH+/n6lpKSopqbmmtafOHFCDzzwgHJzc3XkyBH9+Mc/1urVq/XOO+/4PCwAAAg+Pj8O/v7779f9999/zetra2uVkJCgqqoqSZLdbtf777+vX/3qV8rPz/f17QEAQJCZ9GtGnE6n8vLyvLbl5+fL6XRedp/BwUH19vZ6fQEAgOA06R+U53K5FBMT47UtJiZGvb29GhgYUHh4+CX7VFZWasuWLZM9GgDATy5cuKDOzs6rrhsYGFBXV5dsNtuY//3/b0lJSYqIiPDXiAhgAfmpvWVlZXI4HKPfj3wEMQAgMHV2dio9Pd2vx2xtbVVaWppfj4nANOkxEhsbq56eHq9tPT09ioqKumwVW61WWa3WyR4NAOAnSUlJam1tveq6jo4OlZSUaPfu3bLb7Vc9Jm4Mkx4jWVlZ2rdvn9e2d999V1lZWZP91gCA6yQiIsKnsxh2u52zHhjlc4x88cUXOn78+Oj3J06c0JEjR3TbbbfpzjvvVFlZmT799FP98Y9/lCQ9+uij2r59u37605/qBz/4gf7+97/rz3/+s/bu3eu/nwJBw+12q6WlRd3d3YqLi1NOTo4sFovpsQAAk8jnu2kOHz6s+fPna/78+ZIkh8Oh+fPnq7y8XJLU3d2tkydPjq5PSEjQ3r179e677yolJUVVVVV65ZVXuK0Xl6ivr1diYqJyc3O1YsUK5ebmKjExUfX19aZHAwBMIp/PjCxevFjDw8OXfX2sp6suXrxYH3zwga9vhRtIfX29iouLVVBQoNdff13z5s1Te3u7KioqVFxcrLq6OhUVFZkeEwAwCfhsGhjndru1bt06FRQU6K233tLFixf117/+VRcvXtRbb72lgoICrV+/Xm632/SoAIBJQIzAuJaWFnV1dSk7O1tz5871+jXN3LlzlZWVpRMnTqilpcX0qACASUCMwLju7m5JXz5fJjk5WU6nU319fXI6nUpOTtbGjRu91gEAgktAPvQMN5aZM2dKku699141NDQoNPTLRl64cKEaGhr0zW9+UwcOHBhdBwAILpwZQcALCQkxPQIAYBIRIzDuzJkzkqQDBw6osLDQ69c0hYWFOnDggNc6AEBwIUZgXFxcnCSpoqJCH374obKzsxUVFaXs7Gy1t7fr+eef91oHAAguXDMC43JycmSz2XTw4EEdPXpUBw4cGH0C66JFi/Tggw8qISFBOTk5pkcFAEwCzozAOIvFoqqqKjU2NurBBx+U1WpVQUGBrFarHnzwQTU2Nmrr1q08Fh4AghRnRhAQioqKVFdXp3Xr1ik7O3t0e0JCAk9fBYAgR4wgYBQVFWnp0qV8UB4A3GCIEQQUi8WixYsXmx4DAHAdcc0IAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjLrJ9ADAf3O73WppaVF3d7fi4uKUk5Mji8VieiwAwCTizAgCRn19vRITE5Wbm6sVK1YoNzdXiYmJqq+vNz0aAGASESMICPX19SouLlZycrKcTqf6+vrkdDqVnJys4uJiggQAgljI8PDwsOkhrqa3t1czZszQ+fPnFRUVZXoc+Jnb7VZiYqKSk5PV0NCg0NCvGtnj8aiwsFDt7e06duwYv7IBpri2tjalp6ertbVVaWlppsfBJLvWv785MwLjWlpa1NXVpY0bN3qFiCSFhoaqrKxMJ06cUEtLi6EJAQCTiRiBcd3d3ZKkefPmjfn6yPaRdQCA4EKMwLi4uDhJUnt7+5ivj2wfWQcACC7ECIzLycmRzWZTRUWFPB6P12sej0eVlZVKSEhQTk6OoQkBAJOJGIFxFotFVVVVamxsVGFhodfdNIWFhWpsbNTWrVu5eBUAghQPPUNAKCoqUl1dndatW6fs7OzR7QkJCaqrq1NRUZHB6QAAk4kYQcAoKirS0qVLeQIrANxgiBEEFIvFosWLF5seAwBwHXHNCAAAMIoYAQAARo0rRmpqamSz2RQWFqbMzEwdOnToiuurq6v1jW98Q+Hh4YqPj9dTTz2lixcvjmtgAAAQXHyOkT179sjhcGjz5s1qa2tTSkqK8vPzdebMmTHXv/baa9qwYYM2b96sjo4Ovfrqq9qzZ482btw44eEBAMDU53OMbNu2TWvWrFFpaanuuusu1dbWKiIiQjt37hxz/cGDB7Vo0SKtWLFCNptN9913n5YvX37VsykAAODG4FOMDA0NqbW1VXl5eV8dIDRUeXl5cjqdY+6TnZ2t1tbW0fj4+OOPtW/fPn33u9+97PsMDg6qt7fX6wsAAAQnn27tPXfunNxut2JiYry2x8TEqLOzc8x9VqxYoXPnzunee+/V8PCw/vOf/+jRRx+94q9pKisrtWXLFl9GAwAAU9Sk303T3NysiooK/fa3v1VbW5vq6+u1d+9ePffcc5fdp6ysTOfPnx/9OnXq1GSPCQAADPHpzEh0dLQsFot6enq8tvf09Cg2NnbMfZ599lk99NBDWr16tSQpOTlZ/f39euSRR/TMM88oNPTSHrJarbJarb6MBgAApiifzoxMmzZN6enpampqGt3m8XjU1NSkrKysMfe5cOHCJcEx8njv4eFhX+cFAABBxufHwTscDq1atUoZGRlasGCBqqur1d/fr9LSUknSypUrNXv2bFVWVkqSlixZom3btmn+/PnKzMzU8ePH9eyzz2rJkiV85ggAAPA9RpYtW6azZ8+qvLxcLpdLqamp2r9//+hFrSdPnvQ6E7Jp0yaFhIRo06ZN+vTTT3X77bdryZIlev755/33UwAAJtWxY8fU19c34eN0dHR4/XMiIiMjNWfOnAkfB+aFDE+B35X09vZqxowZOn/+vKKiokyPAwA3lGPHjmnu3LmmxxjT0aNHCZIAdq1/f/OpvQCAKxo5I7J7927Z7fYJHWtgYEBdXV2y2WwKDw8f93E6OjpUUlLil7M1MI8YAQBcE7vdrrS0tAkfZ9GiRX6YBsGEGEFAcbvdamlpUXd3t+Li4pSTk8OFzgAQ5Cb9oWfAtaqvr1diYqJyc3O1YsUK5ebmKjExUfX19aZHAwBMImIEAaG+vl7FxcVKTk6W0+lUX1+fnE6nkpOTVVxcTJAAQBAjRmCc2+3WunXrVFBQoIaGBi1cuFDTp0/XwoUL1dDQoIKCAq1fv15ut9v0qACASUCMwLiWlhZ1dXVp48aNlzytNzQ0VGVlZTpx4oRaWloMTQgAmEzECIzr7u6WJM2bN2/M10e2j6wDAAQXYgTGxcXFSZLa29vldrvV3Nys119/Xc3NzXK73Wpvb/daBwAILtzaC+NycnJks9n0xBNP6OzZs/rkk09GX/va176m22+/XQkJCcrJyTE4JQBgsnBmBMZZLBZ973vf0+HDh3Xx4kXt2LFDp0+f1o4dO3Tx4kUdPnxYxcXFPG8EAIIUMQLj3G633nzzTWVkZCg8PFyPPPKIZs2apUceeUQRERHKyMhQXV0dd9MAQJDi1zQwbuRumtdff1333HPPJU9gPXTokLKzs9XS0qLFixebHhcA4GfECIz777tpLBbLJcHB3TQAENz4NQ2M+++7acbC3TQAENyIERg3cjdNRUWFPB6P12sej0eVlZXcTQMAQYwYgXEWi0VVVVVqbGxUYWGh12fTFBYWqrGxUVu3buVuGgAIUlwzgoBQVFSkuro6rVu3TtnZ2aPbExISVFdXp6KiIoPTAQAmEzGCgFFUVKSlS5decjcNZ0QAILgRIwgoY91NAwAIblwzAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQPPUNAcbvdPIEVAG4wnBlBwKivr1diYqJyc3O1YsUK5ebmKjExUfX19aZHAwBMImIEAaG+vl7FxcVKTk72+tTe5ORkFRcXEyQAEMSIERjndru1bt06FRQUqKGhQQsXLtT06dO1cOFCNTQ0qKCgQOvXr5fb7TY9KgBgEhAjMK6lpUVdXV3auHGjQkO9/5UMDQ1VWVmZTpw4oZaWFkMTAgAmEzEC47q7uyVJ8+bNG/P1ke0j6wAAwYUYgXFxcXGSpPb29jFfH9k+sg4AEFyIERiXk5Mjm82miooKeTwer9c8Ho8qKyuVkJCgnJwcQxMCACYTMQLjLBaLqqqq1NjYqMLCQq+7aQoLC9XY2KitW7fyvBEACFI89AwBoaioSHV1dVq3bp2ys7NHtyckJKiurk5FRUUGpwMATCZiBAGjqKhIS5cu5QmsAHCDIUYQUCwWixYvXmx6DADAdcQ1IwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCK54zgurlw4YI6Ozuvum5gYEBdXV2y2WwKDw+/4tqkpCRFRET4a0QAgAHECK6bzs5Opaen+/WYra2tSktL8+sxAQDXFzGC6yYpKUmtra1XXdfR0aGSkhLt3r1bdrv9qscEAExtxAium4iICJ/OYtjtds56AMANgAtYAQCAUcQIAAAwihgBAABGESMAAMAoYgQAABg1rhipqamRzWZTWFiYMjMzdejQoSuu//zzz/X4448rLi5OVqtVc+fO1b59+8Y1MAAACC4+39q7Z88eORwO1dbWKjMzU9XV1crPz9dHH32kmTNnXrJ+aGhI3/72tzVz5kzV1dVp9uzZ+uSTT3TLLbf4Y34AADDF+Rwj27Zt05o1a1RaWipJqq2t1d69e7Vz505t2LDhkvU7d+7UZ599poMHD+rmm2+WJNlstolNDQAAgoZPv6YZGhpSa2ur8vLyvjpAaKjy8vLkdDrH3Ocvf/mLsrKy9PjjjysmJkbz5s1TRUWF3G73Zd9ncHBQvb29Xl8AACA4+RQj586dk9vtVkxMjNf2mJgYuVyuMff5+OOPVVdXJ7fbrX379unZZ59VVVWVfvGLX1z2fSorKzVjxozRr/j4eF/GBAAAU8ik303j8Xg0c+ZM7dixQ+np6Vq2bJmeeeYZ1dbWXnafsrIynT9/fvTr1KlTkz0mAAAwxKdrRqKjo2WxWNTT0+O1vaenR7GxsWPuExcXp5tvvlkWi2V0m91ul8vl0tDQkKZNm3bJPlarVVar1ZfRAADAFOXTmZFp06YpPT1dTU1No9s8Ho+ampqUlZU15j6LFi3S8ePH5fF4RrcdPXpUcXFxY4YIAAC4sfj8axqHw6GXX35Zf/jDH9TR0aHHHntM/f39o3fXrFy5UmVlZaPrH3vsMX322Wd68skndfToUe3du1cVFRV6/PHH/fdTAACAKcvnW3uXLVums2fPqry8XC6XS6mpqdq/f//oRa0nT55UaOhXjRMfH6933nlHTz31lO6++27Nnj1bTz75pJ5++mn//RQAAGDK8jlGJGnt2rVau3btmK81Nzdfsi0rK0v//Oc/x/NWAAAgyPHZNAAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEbdNJ6dampq9OKLL8rlciklJUW/+c1vtGDBgqvu98Ybb2j58uVaunSpGhoaxvPWAAADYqeHKPzzo9LpwPh/2PDPjyp2eojpMeAnPsfInj175HA4VFtbq8zMTFVXVys/P18fffSRZs6cedn9urq6tH79euXk5ExoYADA9ffD9Gmyv/dD6T3Tk3zJri9nQnDwOUa2bdumNWvWqLS0VJJUW1urvXv3aufOndqwYcOY+7jdbn3/+9/Xli1b1NLSos8//3xCQwMArq/ftw5pWfku2ZOSTI8iSero7NTvq1bof0wPAr/wKUaGhobU2tqqsrKy0W2hoaHKy8uT0+m87H4///nPNXPmTD388MNqaWkZ/7QAACNcXwxr4Ja50qxU06NIkgZcHrm+GDY9BvzEpxg5d+6c3G63YmJivLbHxMSos7NzzH3ef/99vfrqqzpy5Mg1v8/g4KAGBwdHv+/t7fVlTAAAMIVM6pVIfX19euihh/Tyyy8rOjr6mverrKzUjBkzRr/i4+MncUoAAGCST2dGoqOjZbFY1NPT47W9p6dHsbGxl6z/17/+pa6uLi1ZsmR0m8fj+fKNb7pJH330kb7+9a9fsl9ZWZkcDsfo9729vQQJAABByqcYmTZtmtLT09XU1KTCwkJJX8ZFU1OT1q5de8n6pKQkffjhh17bNm3apL6+Pr300kuXDQyr1Sqr1erLaAAAYIry+W4ah8OhVatWKSMjQwsWLFB1dbX6+/tH765ZuXKlZs+ercrKSoWFhWnevHle+99yyy2SdMl2AABwY/I5RpYtW6azZ8+qvLxcLpdLqamp2r9//+hFrSdPnlRoaGA8FAcAAAS+cT2Bde3atWP+WkaSmpubr7jvrl27xvOWAAAgSHEKAwAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGHWT6QEQPI4dO6a+vr4JH6ejo8PrnxMRGRmpOXPmTPg4AIDJQ4zAL44dO6a5c+f69ZglJSV+Oc7Ro0cJEgAIYMQI/GLkjMju3btlt9sndKyBgQF1dXXJZrMpPDx83Mfp6OhQSUmJX87WAAAmDzECv7Lb7UpLS5vwcRYtWuSHaQAAUwEXsAIAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUeOKkZqaGtlsNoWFhSkzM1OHDh267NqXX35ZOTk5uvXWW3XrrbcqLy/viusBAMCNxecY2bNnjxwOhzZv3qy2tjalpKQoPz9fZ86cGXN9c3Ozli9frn/84x9yOp2Kj4/Xfffdp08//XTCwwMAgKnP5xjZtm2b1qxZo9LSUt11112qra1VRESEdu7cOeb6P/3pT/rRj36k1NRUJSUl6ZVXXpHH41FTU9OEhwcAAFOfTzEyNDSk1tZW5eXlfXWA0FDl5eXJ6XRe0zEuXLigf//737rtttsuu2ZwcFC9vb1eXwAAIDj5FCPnzp2T2+1WTEyM1/aYmBi5XK5rOsbTTz+tWbNmeQXN/1dZWakZM2aMfsXHx/syJgAAmEKu6900L7zwgt544w29/fbbCgsLu+y6srIynT9/fvTr1KlT13FKAABwPd3ky+Lo6GhZLBb19PR4be/p6VFsbOwV9926dateeOEF/e1vf9Pdd999xbVWq1VWq9WX0QAAwBTl05mRadOmKT093evi05GLUbOysi673y9/+Us999xz2r9/vzIyMsY/LQAACDo+nRmRJIfDoVWrVikjI0MLFixQdXW1+vv7VVpaKklauXKlZs+ercrKSknS//7v/6q8vFyvvfaabDbb6LUl06dP1/Tp0/34owAAgKnI5xhZtmyZzp49q/LycrlcLqWmpmr//v2jF7WePHlSoaFfnXD53e9+p6GhIRUXF3sdZ/PmzfrZz342sekBAMCU53OMSNLatWu1du3aMV9rbm72+r6rq2s8bwEAAG4QfDYNAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMCocX02DQDgxnHhwgVJUltb24SPNTAwoK6uLtlsNoWHh4/7OB0dHROeBYGDGAEAXFFnZ6ckac2aNYYnuVRkZKTpEeAHxAgA4IoKCwslSUlJSYqIiJjQsTo6OlRSUqLdu3fLbrdP6FiRkZGaM2fOhI6BwECMAACuKDo6WqtXr/brMe12u9LS0vx6TExdXMAKAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMusn0AAgesdNDFP75Uel0YDRu+OdHFTs9xPQYAICrIEbgNz9Mnyb7ez+U3jM9yZfs+nImAEBgI0bgN79vHdKy8l2yJyWZHkWS1NHZqd9XrdD/mB4EAHBFxAj8xvXFsAZumSvNSjU9iiRpwOWR64th02MAAK4iMH65DwAAbljECAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIy6yfQACA4XLlyQJLW1tU34WAMDA+rq6pLNZlN4ePi4j9PR0THhWQAAk48YgV90dnZKktasWWN4kktFRkaaHgEAcAXECPyisLBQkpSUlKSIiIgJHaujo0MlJSXavXu37Hb7hI4VGRmpOXPmTOgYAIDJRYzAL6Kjo7V69Wq/HtNutystLc2vxwQABJ5xXcBaU1Mjm82msLAwZWZm6tChQ1dc/+abbyopKUlhYWFKTk7Wvn37xjUsAAAIPj7HyJ49e+RwOLR582a1tbUpJSVF+fn5OnPmzJjrDx48qOXLl+vhhx/WBx98oMLCQhUWFqq9vX3CwwMAgKnP5xjZtm2b1qxZo9LSUt11112qra1VRESEdu7cOeb6l156Sd/5znf0k5/8RHa7Xc8995zS0tK0ffv2CQ8PAACmPp+uGRkaGlJra6vKyspGt4WGhiovL09Op3PMfZxOpxwOh9e2/Px8NTQ0XPZ9BgcHNTg4OPp9b2+vL2MiQF24cGH0rpsrGbkl91puzfXHBbMAJo4/35gIn2Lk3LlzcrvdiomJ8doeExNz2X8JXS7XmOtdLtdl36eyslJbtmzxZTRMAZ2dnUpPT7/m9SUlJVdd09raykWuQADgzzcmIiDvpikrK/M6m9Lb26v4+HiDE8EfkpKS1NraetV1vjz0LCkpyV/jAZgA/nxjInyKkejoaFksFvX09Hht7+npUWxs7Jj7xMbG+rRekqxWq6xWqy+jYQqIiIi45v/LWbRo0SRPA8Cf+PONifDpAtZp06YpPT1dTU1No9s8Ho+ampqUlZU15j5ZWVle6yXp3Xffvex6AABwY/H51zQOh0OrVq1SRkaGFixYoOrqavX396u0tFSStHLlSs2ePVuVlZWSpCeffFLf+ta3VFVVpQceeEBvvPGGDh8+rB07dvj3JwEAAFOSzzGybNkynT17VuXl5XK5XEpNTdX+/ftHL1I9efKkQkO/OuGSnZ2t1157TZs2bdLGjRs1Z84cNTQ0aN68ef77KQAAwJQVMjw8PGx6iKvp7e3VjBkzdP78eUVFRZkeBwAAXINr/ft7XI+DBwAA8BdiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwCifHwdvwshDYnt7ew1PAgAArtXI39tXe9j7lIiRvr4+SVJ8fLzhSQAAgK/6+vo0Y8aMy74+JT6bxuPx6PTp04qMjFRISIjpcTDJent7FR8fr1OnTvFZRECQ4c/3jWV4eFh9fX2aNWuW14fo/n9T4sxIaGio7rjjDtNj4DqLioriP1ZAkOLP943jSmdERnABKwAAMIoYAQAARhEjCDhWq1WbN2+W1Wo1PQoAP+PPN8YyJS5gBQAAwYszIwAAwChiBAAAGEWMAAAAo4gRAABgFDGCgFJTUyObzaawsDBlZmbq0KFDpkcC4AfvvfeelixZolmzZikkJEQNDQ2mR0IAIUYQMPbs2SOHw6HNmzerra1NKSkpys/P15kzZ0yPBmCC+vv7lZKSopqaGtOjIABxay8CRmZmpu655x5t375d0pefSRQfH68nnnhCGzZsMDwdAH8JCQnR22+/rcLCQtOjIEBwZgQBYWhoSK2trcrLyxvdFhoaqry8PDmdToOTAQAmGzGCgHDu3Dm53W7FxMR4bY+JiZHL5TI0FQDgeiBGAACAUcQIAkJ0dLQsFot6enq8tvf09Cg2NtbQVACA64EYQUCYNm2a0tPT1dTUNLrN4/GoqalJWVlZBicDAEy2m0wPAIxwOBxatWqVMjIytGDBAlVXV6u/v1+lpaWmRwMwQV988YWOHz8++v2JEyd05MgR3XbbbbrzzjsNToZAwK29CCjbt2/Xiy++KJfLpdTUVP36179WZmam6bEATFBzc7Nyc3Mv2b5q1Srt2rXr+g+EgEKMAAAAo7hmBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACM+j/Gdu5zzUktpAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_predict = model.predict(x_test).flatten()\n",
    "data = {0: y_predict[y_test==0], 1: y_predict[y_test==1]}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data.values())\n",
    "ax.set_xticklabels(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0pTXap1nBq5"
   },
   "source": [
    "- Interpreting the results\n",
    " - Not too great:\n",
    "   - The loss is barely being optimised after about 10 epochs\n",
    "   - The validation accuracy is worse then the classical ML baseline (barely over 0.7 in most runs as opposed to nearly 0.76)\n",
    " - The reasons:\n",
    "   - More or less default settings of the model\n",
    "   - More importantly, though, there's no preprocessing of the rather noisy and skewed input data (see for instance [this](https://towardsdatascience.com/pima-indian-diabetes-prediction-7573698bd5fe) or [this](https://www.kaggle.com/code/atulnet/pima-diabetes-keras-implementation) blog post, where examples of detailed exploratory analysis and input data transformations are described)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr1fmV_UnmDZ"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. Developing your own deep learning classifier\n",
    "- Your task is to predict which passengers survived the Titanic disaster, as described in the [Kaggle](https://www.kaggle.com) challenge on [Machine Learning from Disaster](https://www.kaggle.com/c/titanic/overview).\n",
    "\n",
    "![titanic](https://www.fi.muni.cz/~novacek/courses/pb016/labs/img/titanic.jpg)\n",
    "\n",
    "- Split into groups (min 2, max 4 people).\n",
    "- Register at [Kaggle](https://www.kaggle.com/) so that you can officially participate in the [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/overview) competition  (one account per group is enough).\n",
    "- Then, use a deep learning library ([Keras](https://keras.io/) might be the easiest option for newbies, but feel free to use for instance [PyTorch](https://pytorch.org/) if that's what you're already comfortable with) to solve the Titanic survivors' prediction problem as follows:\n",
    " - Get the challenge [data](https://www.kaggle.com/c/titanic/data) via the URLs in the notebook below.\n",
    " - Design a simple neural model for classification of (non)survivors using Keras.\n",
    " - Train the model on the `train.csv` dataset (after possibly preprocessing the data).\n",
    " - Use the trained model to predict the labels of the set `test.csv` (i.e., the values ​​of the column _\"survived\"_; for more details, see the competition documentation itself).\n",
    " - [Upload results](https://www.kaggle.com/c/titanic/submit) on Kaggle.\n",
    "- Discuss your model and score with the lab tutor! The collaborating members of the group with the best relative results and/or an interesting/elegant/efficient/unusual model can earn bonus points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWIcu-WFrB-N"
   },
   "source": [
    "### Loading the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "kzC3yqpHniPM"
   },
   "outputs": [],
   "source": [
    "# importing pandas, just in case it wasn't imported before\n",
    "import pandas as pd\n",
    "\n",
    "# loading the train and test data using pandas\n",
    "\n",
    "df_train = pd.read_csv('https://www.fi.muni.cz/~novacek/courses/pb016/labs/data/12/titanic/train.csv',\\\n",
    "                       index_col='PassengerId')\n",
    "df_test = pd.read_csv('https://www.fi.muni.cz/~novacek/courses/pb016/labs/data/12/titanic/test.csv', \\\n",
    "                      index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IA4hfwGR26oP"
   },
   "source": [
    "### Checking out the train and test data contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "agY80lGO2_Sa",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "3RAwtMw53LMa",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7jqJu5SrGec"
   },
   "source": [
    "### Developing the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1</td>\n",
       "      <td>Newell, Mr. Arthur Webster</td>\n",
       "      <td>male</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35273</td>\n",
       "      <td>113.2750</td>\n",
       "      <td>D48</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3</td>\n",
       "      <td>Farrell, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367232</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>3</td>\n",
       "      <td>McCormack, Mr. Thomas Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367228</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>3</td>\n",
       "      <td>Jonkoff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349204</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2</td>\n",
       "      <td>Angle, Mrs. William A (Florence \"Mary\" Agnes H...</td>\n",
       "      <td>female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>226875</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1</td>\n",
       "      <td>Bradley, Mr. George (\"George Arthur Brayton\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111427</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>3</td>\n",
       "      <td>Lefebre, Miss. Jeannie</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4133</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>3</td>\n",
       "      <td>Ohman, Miss. Velin</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347085</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>Ilett, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SO/C 14885</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "660               1                         Newell, Mr. Arthur Webster   \n",
       "526               3                                 Farrell, Mr. James   \n",
       "829               3                       McCormack, Mr. Thomas Joseph   \n",
       "754               3                                 Jonkoff, Mr. Lalio   \n",
       "519               2  Angle, Mrs. William A (Florence \"Mary\" Agnes H...   \n",
       "...             ...                                                ...   \n",
       "508               1      Bradley, Mr. George (\"George Arthur Brayton\")   \n",
       "486               3                             Lefebre, Miss. Jeannie   \n",
       "11                3                    Sandstrom, Miss. Marguerite Rut   \n",
       "555               3                                 Ohman, Miss. Velin   \n",
       "85                2                                Ilett, Miss. Bertha   \n",
       "\n",
       "                Sex   Age  SibSp  Parch      Ticket      Fare Cabin Embarked  \n",
       "PassengerId                                                                   \n",
       "660            male  58.0      0      2       35273  113.2750   D48        C  \n",
       "526            male  40.5      0      0      367232    7.7500   NaN        Q  \n",
       "829            male   NaN      0      0      367228    7.7500   NaN        Q  \n",
       "754            male  23.0      0      0      349204    7.8958   NaN        S  \n",
       "519          female  36.0      1      0      226875   26.0000   NaN        S  \n",
       "...             ...   ...    ...    ...         ...       ...   ...      ...  \n",
       "508            male   NaN      0      0      111427   26.5500   NaN        S  \n",
       "486          female   NaN      3      1        4133   25.4667   NaN        S  \n",
       "11           female   4.0      1      1     PP 9549   16.7000    G6        S  \n",
       "555          female  22.0      0      0      347085    7.7750   NaN        S  \n",
       "85           female  17.0      0      0  SO/C 14885   10.5000   NaN        S  \n",
       "\n",
       "[713 rows x 10 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_train.sample(frac=0.8,random_state=200)\n",
    "valid = df_train.drop(train.index)\n",
    "\n",
    "x_train = train.drop('Survived',axis=1)\n",
    "y_train = train.Survived.values.reshape(-1, 1)\n",
    "x_valid = valid.drop('Survived',axis=1)\n",
    "y_valid = valid.Survived.values.reshape(-1, 1)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "jESxfpu-rIzx"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from numpy import nan\n",
    "\n",
    "features_to_drop = [\"Name\", \"Ticket\"]\n",
    "categorical_features = [\"Pclass\", \"Sex\", \"Parch\", \"Embarked\"]\n",
    "numeric_features = [\"Age\", \"SibSp\", \"Fare\"]\n",
    "special_features = [\"Cabin\"]\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cabin_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"cabinMap\", FunctionTransformer(\n",
    "            func=lambda x: 0 if x is nan else 1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        #(\"spec\", cabin_transformer, special_features),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "classifier = Pipeline(\n",
    "    steps=[\n",
    "        #(\"Dummy\", DummyClassifier()),\n",
    "        (\"MLP\", MLPClassifier(\n",
    "            hidden_layer_sizes=(15, 20, 10, 5),\n",
    "            activation='relu',\n",
    "            solver='adam',\n",
    "            alpha=1e-5,\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"classify\", classifier),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jindmen/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jindmen/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x79c644df0610>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    model, x_valid, y_valid, xticks_rotation=\"vertical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diP58FYa-TYD"
   },
   "source": [
    "### Notes on the solution\n",
    "- Feel free to get inspired on the web, but make sure you understand what you're doing when using someone else's (be it human or AI) code.\n",
    "- A practical note on getting the submission file to be uploaded to Kaggle, if you're working in Google Colab:\n",
    " - You can create the CSV in your virtual environment, for instance using the `submission.to_csv('submission.csv', index=False)` command, assuming the `submission` variable is a _pandas_ data frame object.\n",
    " - Then you can simply download it by first importing the `files` module by the `from google.colab import files` line, and then using the module with the `files.download('submission.csv')` line to store the data on your local machine.\n",
    " - To save you some effort, the following code cell contains the Google Colab code that can take care of the above steps, assuming you have generated the `predictions` variable from the Titanic test set using your trained model's `predict()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "UM4oXPXI8O0l"
   },
   "outputs": [],
   "source": [
    "# the pandas data frame with the results\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': df_test.index,\n",
    "    'Survived': predictions,\n",
    "})\n",
    "\n",
    "# storing the submissions as CSV\n",
    "submission.sort_values('PassengerId', inplace=True)\n",
    "submission.to_csv('submission-example.csv', index=False)\n",
    "\n",
    "# downloading the created CSV file locally\n",
    "# from google.colab import files\n",
    "# files.download('submission-example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "yLjsBHRLnmDa",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "---\n",
    "\n",
    "#### _Final note_ - the materials used in this notebook are original works credited and licensed as follows:\n",
    "- Image of Titanic:\n",
    " - Retrieved from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:St%C3%B6wer_Titanic.jpg)\n",
    " - Author: Willy Stöwer (image reproduction)\n",
    " - License: none (or [Public Domain](https://en.wikipedia.org/wiki/public_domain))\n",
    "- Image of the DL architecture:\n",
    " - See the inline note associated with the image itself."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
